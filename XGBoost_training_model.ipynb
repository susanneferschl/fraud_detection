{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import train_log, eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RSEED=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = pd.read_csv(\"data/yearly_cons.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = df_year.drop('client_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a handler to output logs to the console\n",
    "handler = logging.FileHandler('train.log')\n",
    "\n",
    "# Create a formatter to format the logs\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Add the formatter to the handler\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST Training - unbalanced data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import recall_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X = df_year.drop(['target'], axis=1)\n",
    "y = df_year['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "model = XGBClassifier(random_state=RSEED, n_jobs=-1)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='recall', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Score: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model using balanced data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X = df_year.drop(['target'], axis=1)\n",
    "y = df_year['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=RSEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "model = XGBClassifier(random_state=RSEED, n_jobs=-1)\n",
    "\n",
    "# Initialize RandomizedSearchCV with Recall as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=3, scoring='recall', verbose=1, n_jobs=-1, random_state=RSEED)\n",
    "\n",
    "# Fit the random search to the resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model_0 = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model_0.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f'Best Parameters: {random_search.best_params_}')\n",
    "print(f'Best Score: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score, roc_auc_score, f1_score\n",
    "# print(\"Best Parameters: \", grid_search.best_params_) \n",
    "print(\"Test Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"Test AUC: \", roc_auc_score(y_test, best_model_0.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval\n",
    "eval(best_model_0.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using best parameter selection\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X = df_year.drop(['target'], axis=1)\n",
    "y = df_year['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=RSEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [900, 1000, 1100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [6, 7, 8],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.9, 1.0, 1.1],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0.05, 0.1, 0.15],\n",
    "    'reg_lambda': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "model = XGBClassifier(random_state=RSEED, n_jobs=-1)\n",
    "\n",
    "# Initialize RandomizedSearchCV with Recall as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=3, scoring='recall', verbose=1, n_jobs=-1, random_state=RSEED)\n",
    "\n",
    "# Fit the random search to the resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model_1 = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model_1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f'Best Parameters: {random_search.best_params_}')\n",
    "print(f'Best Score: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using best parameter selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X = df_year.drop(['target'], axis=1)\n",
    "y = df_year['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=RSEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 1000, 1100],\n",
    "    'learning_rate': [0.1, 0.2, 0.25],\n",
    "    'max_depth': [6, 7, 8],\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.15],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "model = XGBClassifier(random_state=RSEED, n_jobs=-1)\n",
    "\n",
    "# Initialize RandomizedSearchCV with Recall as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=3, scoring='recall', verbose=1, n_jobs=-1, random_state=RSEED)\n",
    "\n",
    "# Fit the random search to the resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model_1 = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model_1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f'Best Parameters: {random_search.best_params_}')\n",
    "print(f'Best Score: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl = pd.read_csv(\"data/agg_lvl.csv\", low_memory=False) \n",
    "agg_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(agg_lvl['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_lvl['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X = df_year.drop(['target'], axis=1)\n",
    "y = df_year['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=RSEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "model = XGBClassifier(random_state=RSEED, n_jobs=-1)\n",
    "\n",
    "# Initialize RandomizedSearchCV with Recall as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=3, scoring='recall', verbose=1, n_jobs=-1, random_state=RSEED)\n",
    "\n",
    "# Fit the random search to the resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model_0 = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model_0.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f'Best Parameters: {random_search.best_params_}')\n",
    "print(f'Best Score: {random_search.best_score_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
